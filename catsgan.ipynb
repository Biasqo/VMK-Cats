{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "catsgan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "Y8YfNtIf4qcD"
      },
      "source": [
        "# Основные библиотеки\n",
        "import numpy as np \n",
        "from numpy.random import random\n",
        "from scipy.linalg import sqrtm\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "from torch import device\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWvDfdId4qcE"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR4Kr9_y4wxH",
        "outputId": "db8a8325-0900-4229-ab95-ea5301559e64"
      },
      "source": [
        "# Датасет с гугл диска\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0071MKJ40eN",
        "outputId": "5011b674-38dd-4879-a413-1a9a5dc7e398"
      },
      "source": [
        "!ls /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " archive.zip   cats  'Colab Notebooks'\t nauk.rar   Timetable.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZWUM8W4qcF"
      },
      "source": [
        "direc = '/content/gdrive/MyDrive/cats'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqymf-ua4qcF",
        "outputId": "eb5dc68d-5c21-4267-b90d-575bdb9d6609"
      },
      "source": [
        "print(os.listdir(direc + '/cats')[:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['94.jpg', '9598.jpg', '9661.jpg', '9867.jpg', '9352.jpg', '9513.jpg', '9973.jpg', '9116.jpg', '9110.jpg', '8990.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnzfyNi34qcH"
      },
      "source": [
        "# batch = 64\n",
        "image_size = 64\n",
        "batch_size = 64\n",
        "latent_size= 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "\n",
        "train = ImageFolder(direc, transform=tt.Compose([ tt.Resize(image_size),\n",
        "                                                        tt.CenterCrop(image_size),\n",
        "                                                        tt.ToTensor(),\n",
        "                                                        tt.Normalize(*stats)]))\n",
        " \n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=3, pin_memory=True) # Загрузка датасета"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_3KF3OF4qcI"
      },
      "source": [
        "# Генератор\n",
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh())\n",
        "    # out: 3 x 64 x 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpZtnLHV4qcJ"
      },
      "source": [
        "# Дискриминатор\n",
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EwgcRMg4qcJ"
      },
      "source": [
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vye9EyE4qcJ"
      },
      "source": [
        "# Сохранение изображеений во время эпохи\n",
        "\n",
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "def save_samples(index, latent_tensors, show=True):\n",
        "    fake_images = generator(latent_tensors).to(device)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J0YFbUy4qcK"
      },
      "source": [
        "# Обучение дискриминатора\n",
        "def train_discriminator(real_images, opt_d):\n",
        "    \n",
        "    # Обнуление градиентов\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    # Доставка настоящих изображений\n",
        "    real_preds = discriminator(real_images).to(device) \n",
        "    real_targets = torch.ones(real_images.size(0), 1).to(device) \n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    # Генерация фейков\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "    fake_images = generator(latent).to(device)  \n",
        "\n",
        "    # Доставка фейков через дискриминатор\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1).to(device)\n",
        "    fake_preds = discriminator(fake_images).to(device)  \n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)  \n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    # Обновление весов\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhSDB4oG4qcL"
      },
      "source": [
        "# Обучение генератора\n",
        "def train_generator(opt_g):\n",
        "\n",
        "    # Обнуление градиентов\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    # Генерация фейков\n",
        "    latent = torch.randn(batch_size, latent_size, 1,1).to(device) # шум\n",
        "    fake_images = generator(latent).to(device) \n",
        "    \n",
        "    # \"Обман\" дискриминатора\n",
        "    preds = discriminator(fake_images).to(device) # предсказания для фейков\n",
        "    targets = torch.ones(batch_size, 1).to(device) # цель 1, чтобы обмануть дискриминатор\n",
        "    loss = F.binary_cross_entropy(preds, targets) # сравнение\n",
        "    \n",
        "    # Обновление весов\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item(), latent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt7QWUXh4qcL"
      },
      "source": [
        "def fit(epochs, lr, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # лосс функции (значения)\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "    \n",
        "    # Оптимизаторы\n",
        "    opt_d = torch.optim.Adam(discriminator.to(device).parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.to(device).parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            \n",
        "            # Обуччение\n",
        "            real_images= real_images.to(device)\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            \n",
        "            loss_g, latent = train_generator(opt_g)\n",
        "            \n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "        \n",
        "        print(\"Эпоха [{}/{}], loss_g: {}, loss_d: {}, real_score: {}, fake_score: {}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    \n",
        "        # Сохранение\n",
        "        save_samples(epoch+start_idx, latent, show=False)\n",
        "    \n",
        "    return losses_g, losses_d, latent, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4nIa3NF4qcL"
      },
      "source": [
        "# Обучение модели\n",
        "# При больших количествах эпох получался mode collapse сети\n",
        "model = fit(epochs=30, lr=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14rklIzo5K4W"
      },
      "source": [
        "!zip -r ./generated.zip ./generated/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyi8WUHF6ave"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"generated.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHpVHotqCVm_"
      },
      "source": [
        "# Сохранение сгенерированных изображений (10000)\n",
        "\n",
        "sample_dir = 'generated_full/cats'\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "def save_samples_full(index, latent_tensors):\n",
        "    fake_images = generator(latent_tensors).to(device)\n",
        "    fake_fname = 'cats-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname))\n",
        "    print('Saving', fake_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krmu2DIQCKpD"
      },
      "source": [
        "# Генерация фейков\n",
        "for i in range(10000):\n",
        "    latent = torch.randn(1, latent_size, 1,1).to(device)\n",
        "    save_samples_full(i, latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu6jwu6jCxUt"
      },
      "source": [
        "!zip -r ./generated_full.zip ./generated_full/cats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ADwOG5lCpjU"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"generated_full.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3sseeIuxH5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91pc47l06cGl"
      },
      "source": [
        "!rm -rf generated\n",
        "!rm -rf generated.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKRhyhSyCm7o"
      },
      "source": [
        "!rm -rf generated_full\n",
        "!rm -rf generated_full.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0e3tujWwB7P"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}